{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AQ0-DAE.ipynb","provenance":[{"file_id":"1mRkB8h08MXPQ0QMyRCW9_DeKHtxAtZMo","timestamp":1626157018778},{"file_id":"1iaPdRDd6Z2Q-_bmtVC90Nt6fgOlp8Jb5","timestamp":1622919164880}],"collapsed_sections":[],"authorship_tag":"ABX9TyOvca/5hmbZwSwXBPlh9NOT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aTh6k0VMXfTT","executionInfo":{"status":"ok","timestamp":1644311600926,"user_tz":-210,"elapsed":1139,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}}},"source":["root_path = \"/content/drive/MyDrive\"\n","import numpy as np\n","import pandas as pd \n","import os\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import  cross_val_predict\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import time\n","from sklearn.model_selection import GridSearchCV"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xa7T8Kt3X2tf","executionInfo":{"status":"ok","timestamp":1644311638324,"user_tz":-210,"elapsed":37407,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"fa872258-5c2e-45f2-a882-3c759b583560"},"source":["from google.colab import drive\n","import tensorflow as tf\n","print(tf.test.gpu_device_name())\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOuDBG1MYbI4","executionInfo":{"status":"ok","timestamp":1644311641600,"user_tz":-210,"elapsed":1035,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"ab7e5519-5211-4198-ec8c-3b66e89581bc"},"source":["# parameters\n","varAOD = 'nAODm'\n","varPM = 'PMc'\n","\n","name = 'train' + \".csv\"\n","path = os.path.join(root_path, 'final_data', name)\n","\n","dftrain = pd.read_csv(path)\n","\n","\n","Xtrain = dftrain[[varAOD, 'lat', 'long', 'Prob_bestm','d2m', 't2m', 'blh',\n","                  'sp', 'lai_hv', 'ws10', 'wd10', 'uvb', 'RH', 'DOY']]\n","ytrain = dftrain.loc[:,['PMc']]\n","\n","scaler = MinMaxScaler()\n","Xstrain = scaler.fit_transform(Xtrain)\n","ytrain = ytrain.to_numpy()\n","\n","print(Xstrain.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(15848, 14)\n"]}]},{"cell_type":"markdown","metadata":{"id":"g4uVWmFLk8Se"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"7XOv6mjPYB2i","executionInfo":{"status":"ok","timestamp":1644311645017,"user_tz":-210,"elapsed":492,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}}},"source":["def plot_history(history):\n","    import matplotlib.pyplot as plt\n","    plt.title(\"Loss\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.plot(history.history['loss'], label='train')\n","    plt.plot(history.history['val_loss'], label='val')\n","    plt.legend()\n","    plt.show()\n","  \n","def get_model_name(k):\n","    return 'model_'+str(k)+'.h5'\n","\n","save_dir = os.path.join(root_path, \"final_data/AQ1-saved_model\")\n","fold_var = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-cPxVzhYayd","executionInfo":{"status":"ok","timestamp":1644311648342,"user_tz":-210,"elapsed":500,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}}},"source":["# train autoencoder for regression with no compression in the bottleneck layer\n","from sklearn.datasets import make_regression\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import ReLU\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.utils import plot_model\n","from matplotlib import pyplot\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","n_inputs = Xstrain.shape[1]\n","\n","# define encoder\n","visible = Input(shape=(n_inputs,))\n","e=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(visible)\n","e=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(16, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","e=Dense(16, activation='relu', kernel_regularizer=l2(1e-3))(e)\n","# define bottleneck\n","n_bottleneck = 10\n","bottleneck = Dense(n_bottleneck)(e)\n","# define decoder, level 1\n","d=Dense(16, activation='relu', kernel_regularizer=l2(1e-3))(bottleneck)\n","d=Dense(16, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","d=Dense(128, activation='relu', kernel_regularizer=l2(1e-3))(d)\n","# output layer\n","output = Dense(n_inputs, activation='linear')(d)\n","# define autoencoder model\n","model = Model(inputs=visible, outputs=output)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UEeAYu16mcMs","executionInfo":{"status":"ok","timestamp":1644312259719,"user_tz":-210,"elapsed":607590,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"37b03af1-d545-4a91-f3fc-836a7d4f311b"},"source":["# compile autoencoder model\n"," \n","opt = Adam(learning_rate=0.0001)\n","model.compile(optimizer=opt, loss='mse')\n","\n","# CREATE CALLBACKS\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, get_model_name(fold_var)), \n","\t\t\t\t\t\t\tmonitor='val_loss', verbose=1, \n","\t\t\t\t\t\t\tsave_best_only=True, mode='min')\n","\n","callbacks_list = [checkpoint]\n","\n","# fit the autoencoder model to reconstruct input\n","history = model.fit(Xstrain, ytrain, epochs=200, verbose=2, validation_split=0.2, callbacks=callbacks_list)\n","# plot val and loss\n","plot_history(history)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\n","Epoch 00001: val_loss improved from inf to 3006.84546, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 8s - loss: 8378.0771 - val_loss: 3006.8455 - 8s/epoch - 20ms/step\n","Epoch 2/200\n","\n","Epoch 00002: val_loss improved from 3006.84546 to 2578.57788, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2950.3899 - val_loss: 2578.5779 - 3s/epoch - 8ms/step\n","Epoch 3/200\n","\n","Epoch 00003: val_loss improved from 2578.57788 to 2259.89014, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2590.5513 - val_loss: 2259.8901 - 3s/epoch - 8ms/step\n","Epoch 4/200\n","\n","Epoch 00004: val_loss improved from 2259.89014 to 2112.30200, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2394.9563 - val_loss: 2112.3020 - 3s/epoch - 8ms/step\n","Epoch 5/200\n","\n","Epoch 00005: val_loss did not improve from 2112.30200\n","397/397 - 3s - loss: 2283.2698 - val_loss: 2204.6140 - 3s/epoch - 7ms/step\n","Epoch 6/200\n","\n","Epoch 00006: val_loss did not improve from 2112.30200\n","397/397 - 3s - loss: 2261.7888 - val_loss: 2259.2122 - 3s/epoch - 7ms/step\n","Epoch 7/200\n","\n","Epoch 00007: val_loss improved from 2112.30200 to 2045.62097, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2208.1934 - val_loss: 2045.6210 - 3s/epoch - 9ms/step\n","Epoch 8/200\n","\n","Epoch 00008: val_loss improved from 2045.62097 to 2001.27600, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2180.9592 - val_loss: 2001.2760 - 3s/epoch - 8ms/step\n","Epoch 9/200\n","\n","Epoch 00009: val_loss did not improve from 2001.27600\n","397/397 - 3s - loss: 2158.3682 - val_loss: 2114.6707 - 3s/epoch - 8ms/step\n","Epoch 10/200\n","\n","Epoch 00010: val_loss improved from 2001.27600 to 1963.30847, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2145.6128 - val_loss: 1963.3085 - 3s/epoch - 8ms/step\n","Epoch 11/200\n","\n","Epoch 00011: val_loss did not improve from 1963.30847\n","397/397 - 3s - loss: 2129.6548 - val_loss: 2009.1962 - 3s/epoch - 7ms/step\n","Epoch 12/200\n","\n","Epoch 00012: val_loss improved from 1963.30847 to 1959.05554, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2115.6150 - val_loss: 1959.0555 - 3s/epoch - 8ms/step\n","Epoch 13/200\n","\n","Epoch 00013: val_loss did not improve from 1959.05554\n","397/397 - 3s - loss: 2103.6619 - val_loss: 1964.9033 - 3s/epoch - 7ms/step\n","Epoch 14/200\n","\n","Epoch 00014: val_loss improved from 1959.05554 to 1929.26819, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 2093.3965 - val_loss: 1929.2682 - 4s/epoch - 9ms/step\n","Epoch 15/200\n","\n","Epoch 00015: val_loss improved from 1929.26819 to 1928.46704, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 5s - loss: 2076.4617 - val_loss: 1928.4670 - 5s/epoch - 14ms/step\n","Epoch 16/200\n","\n","Epoch 00016: val_loss did not improve from 1928.46704\n","397/397 - 3s - loss: 2075.3333 - val_loss: 1930.3099 - 3s/epoch - 7ms/step\n","Epoch 17/200\n","\n","Epoch 00017: val_loss improved from 1928.46704 to 1903.68091, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2065.4639 - val_loss: 1903.6809 - 3s/epoch - 8ms/step\n","Epoch 18/200\n","\n","Epoch 00018: val_loss did not improve from 1903.68091\n","397/397 - 3s - loss: 2058.1475 - val_loss: 1956.5978 - 3s/epoch - 7ms/step\n","Epoch 19/200\n","\n","Epoch 00019: val_loss did not improve from 1903.68091\n","397/397 - 3s - loss: 2048.5051 - val_loss: 1927.1560 - 3s/epoch - 7ms/step\n","Epoch 20/200\n","\n","Epoch 00020: val_loss improved from 1903.68091 to 1891.52637, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2029.3270 - val_loss: 1891.5264 - 3s/epoch - 9ms/step\n","Epoch 21/200\n","\n","Epoch 00021: val_loss improved from 1891.52637 to 1879.91504, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2034.4119 - val_loss: 1879.9150 - 3s/epoch - 8ms/step\n","Epoch 22/200\n","\n","Epoch 00022: val_loss improved from 1879.91504 to 1870.51526, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2008.2303 - val_loss: 1870.5153 - 3s/epoch - 8ms/step\n","Epoch 23/200\n","\n","Epoch 00023: val_loss did not improve from 1870.51526\n","397/397 - 3s - loss: 1986.4642 - val_loss: 1871.5607 - 3s/epoch - 7ms/step\n","Epoch 24/200\n","\n","Epoch 00024: val_loss improved from 1870.51526 to 1866.38000, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1999.4767 - val_loss: 1866.3800 - 3s/epoch - 8ms/step\n","Epoch 25/200\n","\n","Epoch 00025: val_loss did not improve from 1866.38000\n","397/397 - 3s - loss: 1981.3536 - val_loss: 1918.7186 - 3s/epoch - 7ms/step\n","Epoch 26/200\n","\n","Epoch 00026: val_loss improved from 1866.38000 to 1849.06335, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1984.0212 - val_loss: 1849.0634 - 3s/epoch - 8ms/step\n","Epoch 27/200\n","\n","Epoch 00027: val_loss did not improve from 1849.06335\n","397/397 - 3s - loss: 1986.1326 - val_loss: 1903.9762 - 3s/epoch - 7ms/step\n","Epoch 28/200\n","\n","Epoch 00028: val_loss improved from 1849.06335 to 1830.09192, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 2019.7235 - val_loss: 1830.0919 - 3s/epoch - 8ms/step\n","Epoch 29/200\n","\n","Epoch 00029: val_loss did not improve from 1830.09192\n","397/397 - 3s - loss: 1960.5881 - val_loss: 1832.8284 - 3s/epoch - 7ms/step\n","Epoch 30/200\n","\n","Epoch 00030: val_loss did not improve from 1830.09192\n","397/397 - 3s - loss: 1934.9926 - val_loss: 1883.5330 - 3s/epoch - 7ms/step\n","Epoch 31/200\n","\n","Epoch 00031: val_loss improved from 1830.09192 to 1826.88428, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 1934.2422 - val_loss: 1826.8843 - 4s/epoch - 9ms/step\n","Epoch 32/200\n","\n","Epoch 00032: val_loss did not improve from 1826.88428\n","397/397 - 3s - loss: 1928.8857 - val_loss: 1835.7830 - 3s/epoch - 7ms/step\n","Epoch 33/200\n","\n","Epoch 00033: val_loss did not improve from 1826.88428\n","397/397 - 3s - loss: 1908.2548 - val_loss: 1858.7302 - 3s/epoch - 7ms/step\n","Epoch 34/200\n","\n","Epoch 00034: val_loss did not improve from 1826.88428\n","397/397 - 3s - loss: 1899.5193 - val_loss: 2002.0383 - 3s/epoch - 7ms/step\n","Epoch 35/200\n","\n","Epoch 00035: val_loss did not improve from 1826.88428\n","397/397 - 3s - loss: 1937.5236 - val_loss: 1847.8976 - 3s/epoch - 8ms/step\n","Epoch 36/200\n","\n","Epoch 00036: val_loss did not improve from 1826.88428\n","397/397 - 3s - loss: 1894.3898 - val_loss: 2007.9828 - 3s/epoch - 7ms/step\n","Epoch 37/200\n","\n","Epoch 00037: val_loss improved from 1826.88428 to 1816.43408, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 1910.0339 - val_loss: 1816.4341 - 4s/epoch - 9ms/step\n","Epoch 38/200\n","\n","Epoch 00038: val_loss did not improve from 1816.43408\n","397/397 - 3s - loss: 1908.0444 - val_loss: 2013.7390 - 3s/epoch - 7ms/step\n","Epoch 39/200\n","\n","Epoch 00039: val_loss improved from 1816.43408 to 1787.55774, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1889.3799 - val_loss: 1787.5577 - 3s/epoch - 8ms/step\n","Epoch 40/200\n","\n","Epoch 00040: val_loss did not improve from 1787.55774\n","397/397 - 3s - loss: 1875.3196 - val_loss: 1847.2987 - 3s/epoch - 7ms/step\n","Epoch 41/200\n","\n","Epoch 00041: val_loss improved from 1787.55774 to 1785.92651, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1876.1344 - val_loss: 1785.9265 - 3s/epoch - 8ms/step\n","Epoch 42/200\n","\n","Epoch 00042: val_loss did not improve from 1785.92651\n","397/397 - 3s - loss: 1855.4398 - val_loss: 1829.9175 - 3s/epoch - 7ms/step\n","Epoch 43/200\n","\n","Epoch 00043: val_loss did not improve from 1785.92651\n","397/397 - 3s - loss: 1847.5775 - val_loss: 1827.3622 - 3s/epoch - 7ms/step\n","Epoch 44/200\n","\n","Epoch 00044: val_loss did not improve from 1785.92651\n","397/397 - 3s - loss: 1861.4672 - val_loss: 1935.5090 - 3s/epoch - 7ms/step\n","Epoch 45/200\n","\n","Epoch 00045: val_loss did not improve from 1785.92651\n","397/397 - 3s - loss: 1843.5414 - val_loss: 1830.5427 - 3s/epoch - 7ms/step\n","Epoch 46/200\n","\n","Epoch 00046: val_loss improved from 1785.92651 to 1784.29871, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 1817.9408 - val_loss: 1784.2987 - 4s/epoch - 9ms/step\n","Epoch 47/200\n","\n","Epoch 00047: val_loss improved from 1784.29871 to 1781.65564, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1832.0017 - val_loss: 1781.6556 - 3s/epoch - 9ms/step\n","Epoch 48/200\n","\n","Epoch 00048: val_loss improved from 1781.65564 to 1775.03491, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1817.2948 - val_loss: 1775.0349 - 3s/epoch - 8ms/step\n","Epoch 49/200\n","\n","Epoch 00049: val_loss did not improve from 1775.03491\n","397/397 - 3s - loss: 1846.6523 - val_loss: 1907.9680 - 3s/epoch - 7ms/step\n","Epoch 50/200\n","\n","Epoch 00050: val_loss improved from 1775.03491 to 1744.59070, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1797.1154 - val_loss: 1744.5907 - 3s/epoch - 8ms/step\n","Epoch 51/200\n","\n","Epoch 00051: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1805.7312 - val_loss: 1756.3446 - 3s/epoch - 7ms/step\n","Epoch 52/200\n","\n","Epoch 00052: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1787.9937 - val_loss: 1791.8354 - 3s/epoch - 7ms/step\n","Epoch 53/200\n","\n","Epoch 00053: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1780.0243 - val_loss: 1879.4989 - 3s/epoch - 7ms/step\n","Epoch 54/200\n","\n","Epoch 00054: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1783.2715 - val_loss: 1848.8938 - 3s/epoch - 7ms/step\n","Epoch 55/200\n","\n","Epoch 00055: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1771.9125 - val_loss: 1792.1403 - 3s/epoch - 7ms/step\n","Epoch 56/200\n","\n","Epoch 00056: val_loss did not improve from 1744.59070\n","397/397 - 3s - loss: 1764.9076 - val_loss: 1777.9877 - 3s/epoch - 7ms/step\n","Epoch 57/200\n","\n","Epoch 00057: val_loss improved from 1744.59070 to 1742.82825, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 1766.9923 - val_loss: 1742.8282 - 4s/epoch - 10ms/step\n","Epoch 58/200\n","\n","Epoch 00058: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1770.5370 - val_loss: 1751.3423 - 3s/epoch - 7ms/step\n","Epoch 59/200\n","\n","Epoch 00059: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1761.8339 - val_loss: 2118.3616 - 3s/epoch - 7ms/step\n","Epoch 60/200\n","\n","Epoch 00060: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1730.7578 - val_loss: 1745.4249 - 3s/epoch - 8ms/step\n","Epoch 61/200\n","\n","Epoch 00061: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1748.5574 - val_loss: 1756.7910 - 3s/epoch - 7ms/step\n","Epoch 62/200\n","\n","Epoch 00062: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1742.4016 - val_loss: 1982.2542 - 3s/epoch - 7ms/step\n","Epoch 63/200\n","\n","Epoch 00063: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1713.9956 - val_loss: 1748.0271 - 3s/epoch - 7ms/step\n","Epoch 64/200\n","\n","Epoch 00064: val_loss did not improve from 1742.82825\n","397/397 - 3s - loss: 1742.5889 - val_loss: 1798.9043 - 3s/epoch - 8ms/step\n","Epoch 65/200\n","\n","Epoch 00065: val_loss improved from 1742.82825 to 1730.07996, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1703.7794 - val_loss: 1730.0800 - 3s/epoch - 9ms/step\n","Epoch 66/200\n","\n","Epoch 00066: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1698.9379 - val_loss: 1888.3042 - 3s/epoch - 7ms/step\n","Epoch 67/200\n","\n","Epoch 00067: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1688.6736 - val_loss: 2103.1375 - 3s/epoch - 7ms/step\n","Epoch 68/200\n","\n","Epoch 00068: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1723.7565 - val_loss: 1770.1820 - 3s/epoch - 7ms/step\n","Epoch 69/200\n","\n","Epoch 00069: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1686.1089 - val_loss: 1760.6345 - 3s/epoch - 7ms/step\n","Epoch 70/200\n","\n","Epoch 00070: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1695.4647 - val_loss: 1781.4265 - 3s/epoch - 7ms/step\n","Epoch 71/200\n","\n","Epoch 00071: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1693.0475 - val_loss: 1797.0388 - 3s/epoch - 7ms/step\n","Epoch 72/200\n","\n","Epoch 00072: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1666.4075 - val_loss: 1814.1244 - 3s/epoch - 7ms/step\n","Epoch 73/200\n","\n","Epoch 00073: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1671.7620 - val_loss: 1762.6600 - 3s/epoch - 7ms/step\n","Epoch 74/200\n","\n","Epoch 00074: val_loss did not improve from 1730.07996\n","397/397 - 3s - loss: 1678.2563 - val_loss: 2039.5680 - 3s/epoch - 7ms/step\n","Epoch 75/200\n","\n","Epoch 00075: val_loss improved from 1730.07996 to 1713.91101, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 4s - loss: 1668.9940 - val_loss: 1713.9110 - 4s/epoch - 9ms/step\n","Epoch 76/200\n","\n","Epoch 00076: val_loss did not improve from 1713.91101\n","397/397 - 3s - loss: 1659.6531 - val_loss: 1738.8551 - 3s/epoch - 7ms/step\n","Epoch 77/200\n","\n","Epoch 00077: val_loss improved from 1713.91101 to 1709.54529, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1672.3097 - val_loss: 1709.5453 - 3s/epoch - 8ms/step\n","Epoch 78/200\n","\n","Epoch 00078: val_loss did not improve from 1709.54529\n","397/397 - 3s - loss: 1651.4009 - val_loss: 1724.3220 - 3s/epoch - 7ms/step\n","Epoch 79/200\n","\n","Epoch 00079: val_loss did not improve from 1709.54529\n","397/397 - 3s - loss: 1658.7197 - val_loss: 1716.7419 - 3s/epoch - 7ms/step\n","Epoch 80/200\n","\n","Epoch 00080: val_loss improved from 1709.54529 to 1699.25000, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1648.9225 - val_loss: 1699.2500 - 3s/epoch - 8ms/step\n","Epoch 81/200\n","\n","Epoch 00081: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1626.9839 - val_loss: 1725.5032 - 3s/epoch - 7ms/step\n","Epoch 82/200\n","\n","Epoch 00082: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1638.3237 - val_loss: 1799.6091 - 3s/epoch - 7ms/step\n","Epoch 83/200\n","\n","Epoch 00083: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1627.9319 - val_loss: 1723.1862 - 3s/epoch - 7ms/step\n","Epoch 84/200\n","\n","Epoch 00084: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1605.6780 - val_loss: 1769.3823 - 3s/epoch - 7ms/step\n","Epoch 85/200\n","\n","Epoch 00085: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1594.3407 - val_loss: 1741.2557 - 3s/epoch - 7ms/step\n","Epoch 86/200\n","\n","Epoch 00086: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1605.4033 - val_loss: 1734.1469 - 3s/epoch - 7ms/step\n","Epoch 87/200\n","\n","Epoch 00087: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1596.3335 - val_loss: 1918.3673 - 3s/epoch - 8ms/step\n","Epoch 88/200\n","\n","Epoch 00088: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1590.9696 - val_loss: 1767.9647 - 3s/epoch - 7ms/step\n","Epoch 89/200\n","\n","Epoch 00089: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1585.4038 - val_loss: 1733.2235 - 3s/epoch - 7ms/step\n","Epoch 90/200\n","\n","Epoch 00090: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1573.4042 - val_loss: 1765.6776 - 3s/epoch - 7ms/step\n","Epoch 91/200\n","\n","Epoch 00091: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1568.1925 - val_loss: 1738.7118 - 3s/epoch - 7ms/step\n","Epoch 92/200\n","\n","Epoch 00092: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1564.7853 - val_loss: 1751.5114 - 3s/epoch - 7ms/step\n","Epoch 93/200\n","\n","Epoch 00093: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1573.9667 - val_loss: 1734.1206 - 3s/epoch - 7ms/step\n","Epoch 94/200\n","\n","Epoch 00094: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1571.0955 - val_loss: 1859.6877 - 3s/epoch - 7ms/step\n","Epoch 95/200\n","\n","Epoch 00095: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1552.1947 - val_loss: 1867.9025 - 3s/epoch - 7ms/step\n","Epoch 96/200\n","\n","Epoch 00096: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1528.5552 - val_loss: 1728.9374 - 3s/epoch - 7ms/step\n","Epoch 97/200\n","\n","Epoch 00097: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1569.7496 - val_loss: 1815.9861 - 3s/epoch - 8ms/step\n","Epoch 98/200\n","\n","Epoch 00098: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1519.2574 - val_loss: 1746.5992 - 3s/epoch - 7ms/step\n","Epoch 99/200\n","\n","Epoch 00099: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1529.7388 - val_loss: 1737.4142 - 3s/epoch - 7ms/step\n","Epoch 100/200\n","\n","Epoch 00100: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1525.3804 - val_loss: 1767.2974 - 3s/epoch - 7ms/step\n","Epoch 101/200\n","\n","Epoch 00101: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1508.5460 - val_loss: 1708.3661 - 3s/epoch - 8ms/step\n","Epoch 102/200\n","\n","Epoch 00102: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1490.5406 - val_loss: 1780.0475 - 3s/epoch - 7ms/step\n","Epoch 103/200\n","\n","Epoch 00103: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1510.5541 - val_loss: 1967.0079 - 3s/epoch - 7ms/step\n","Epoch 104/200\n","\n","Epoch 00104: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1501.5317 - val_loss: 1726.5542 - 3s/epoch - 7ms/step\n","Epoch 105/200\n","\n","Epoch 00105: val_loss did not improve from 1699.25000\n","397/397 - 3s - loss: 1492.7334 - val_loss: 1881.9637 - 3s/epoch - 7ms/step\n","Epoch 106/200\n","\n","Epoch 00106: val_loss improved from 1699.25000 to 1696.06787, saving model to /content/drive/MyDrive/final_data/AQ1-saved_model/model_1.h5\n","397/397 - 3s - loss: 1472.4556 - val_loss: 1696.0679 - 3s/epoch - 9ms/step\n","Epoch 107/200\n","\n","Epoch 00107: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1478.2734 - val_loss: 1753.6206 - 3s/epoch - 7ms/step\n","Epoch 108/200\n","\n","Epoch 00108: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1491.2136 - val_loss: 1767.1064 - 3s/epoch - 7ms/step\n","Epoch 109/200\n","\n","Epoch 00109: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1438.6221 - val_loss: 1745.6396 - 3s/epoch - 7ms/step\n","Epoch 110/200\n","\n","Epoch 00110: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1456.7560 - val_loss: 1750.9901 - 3s/epoch - 7ms/step\n","Epoch 111/200\n","\n","Epoch 00111: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1453.5789 - val_loss: 2172.1208 - 3s/epoch - 7ms/step\n","Epoch 112/200\n","\n","Epoch 00112: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1481.0763 - val_loss: 1794.0200 - 3s/epoch - 7ms/step\n","Epoch 113/200\n","\n","Epoch 00113: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1436.3978 - val_loss: 1916.3519 - 3s/epoch - 7ms/step\n","Epoch 114/200\n","\n","Epoch 00114: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1435.4130 - val_loss: 1702.5388 - 3s/epoch - 7ms/step\n","Epoch 115/200\n","\n","Epoch 00115: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1427.3031 - val_loss: 2044.7788 - 3s/epoch - 7ms/step\n","Epoch 116/200\n","\n","Epoch 00116: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1444.2643 - val_loss: 1772.3016 - 3s/epoch - 7ms/step\n","Epoch 117/200\n","\n","Epoch 00117: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1425.6556 - val_loss: 1805.0767 - 3s/epoch - 7ms/step\n","Epoch 118/200\n","\n","Epoch 00118: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1416.0227 - val_loss: 1771.6901 - 3s/epoch - 7ms/step\n","Epoch 119/200\n","\n","Epoch 00119: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1404.5533 - val_loss: 1810.4617 - 3s/epoch - 7ms/step\n","Epoch 120/200\n","\n","Epoch 00120: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1399.9729 - val_loss: 1965.9600 - 3s/epoch - 7ms/step\n","Epoch 121/200\n","\n","Epoch 00121: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1402.8599 - val_loss: 1775.7432 - 3s/epoch - 8ms/step\n","Epoch 122/200\n","\n","Epoch 00122: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1415.0465 - val_loss: 1767.7694 - 3s/epoch - 7ms/step\n","Epoch 123/200\n","\n","Epoch 00123: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1376.8173 - val_loss: 1764.1459 - 3s/epoch - 7ms/step\n","Epoch 124/200\n","\n","Epoch 00124: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1377.5845 - val_loss: 1893.6062 - 3s/epoch - 8ms/step\n","Epoch 125/200\n","\n","Epoch 00125: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1374.0509 - val_loss: 1829.9308 - 3s/epoch - 7ms/step\n","Epoch 126/200\n","\n","Epoch 00126: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1363.3073 - val_loss: 1840.2904 - 3s/epoch - 8ms/step\n","Epoch 127/200\n","\n","Epoch 00127: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1334.7084 - val_loss: 1810.9115 - 3s/epoch - 7ms/step\n","Epoch 128/200\n","\n","Epoch 00128: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1351.9647 - val_loss: 1828.6414 - 3s/epoch - 7ms/step\n","Epoch 129/200\n","\n","Epoch 00129: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1326.2255 - val_loss: 1783.3287 - 3s/epoch - 7ms/step\n","Epoch 130/200\n","\n","Epoch 00130: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1335.6914 - val_loss: 1781.1680 - 3s/epoch - 7ms/step\n","Epoch 131/200\n","\n","Epoch 00131: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1356.8143 - val_loss: 1776.6608 - 3s/epoch - 8ms/step\n","Epoch 132/200\n","\n","Epoch 00132: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1305.0992 - val_loss: 1753.3187 - 3s/epoch - 7ms/step\n","Epoch 133/200\n","\n","Epoch 00133: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1309.5220 - val_loss: 1821.5734 - 3s/epoch - 7ms/step\n","Epoch 134/200\n","\n","Epoch 00134: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1307.7749 - val_loss: 1795.9194 - 3s/epoch - 7ms/step\n","Epoch 135/200\n","\n","Epoch 00135: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1304.5581 - val_loss: 1786.7841 - 3s/epoch - 7ms/step\n","Epoch 136/200\n","\n","Epoch 00136: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1333.8008 - val_loss: 1775.3444 - 3s/epoch - 7ms/step\n","Epoch 137/200\n","\n","Epoch 00137: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1300.4290 - val_loss: 1814.0963 - 3s/epoch - 7ms/step\n","Epoch 138/200\n","\n","Epoch 00138: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1297.8312 - val_loss: 1836.9205 - 3s/epoch - 7ms/step\n","Epoch 139/200\n","\n","Epoch 00139: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1296.5712 - val_loss: 1802.5734 - 3s/epoch - 7ms/step\n","Epoch 140/200\n","\n","Epoch 00140: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1244.3485 - val_loss: 1815.3365 - 3s/epoch - 7ms/step\n","Epoch 141/200\n","\n","Epoch 00141: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1249.9165 - val_loss: 1814.7814 - 3s/epoch - 7ms/step\n","Epoch 142/200\n","\n","Epoch 00142: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1254.6610 - val_loss: 1774.1062 - 3s/epoch - 7ms/step\n","Epoch 143/200\n","\n","Epoch 00143: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1238.4456 - val_loss: 1772.2177 - 3s/epoch - 7ms/step\n","Epoch 144/200\n","\n","Epoch 00144: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1252.0366 - val_loss: 1795.9255 - 3s/epoch - 7ms/step\n","Epoch 145/200\n","\n","Epoch 00145: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1230.5800 - val_loss: 1880.7520 - 3s/epoch - 7ms/step\n","Epoch 146/200\n","\n","Epoch 00146: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1224.7725 - val_loss: 1859.5394 - 3s/epoch - 7ms/step\n","Epoch 147/200\n","\n","Epoch 00147: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1231.8533 - val_loss: 1749.4518 - 3s/epoch - 7ms/step\n","Epoch 148/200\n","\n","Epoch 00148: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1223.2861 - val_loss: 1766.9061 - 3s/epoch - 7ms/step\n","Epoch 149/200\n","\n","Epoch 00149: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1205.9861 - val_loss: 1817.2906 - 3s/epoch - 7ms/step\n","Epoch 150/200\n","\n","Epoch 00150: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1215.5300 - val_loss: 1875.0042 - 3s/epoch - 8ms/step\n","Epoch 151/200\n","\n","Epoch 00151: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1199.0349 - val_loss: 1940.4462 - 3s/epoch - 8ms/step\n","Epoch 152/200\n","\n","Epoch 00152: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1208.3141 - val_loss: 1884.5049 - 3s/epoch - 8ms/step\n","Epoch 153/200\n","\n","Epoch 00153: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1193.6703 - val_loss: 1829.2062 - 3s/epoch - 7ms/step\n","Epoch 154/200\n","\n","Epoch 00154: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1171.5293 - val_loss: 1796.6195 - 3s/epoch - 7ms/step\n","Epoch 155/200\n","\n","Epoch 00155: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1183.2327 - val_loss: 2249.0317 - 3s/epoch - 8ms/step\n","Epoch 156/200\n","\n","Epoch 00156: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1195.0630 - val_loss: 1872.9326 - 3s/epoch - 8ms/step\n","Epoch 157/200\n","\n","Epoch 00157: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1178.9385 - val_loss: 1804.9580 - 3s/epoch - 7ms/step\n","Epoch 158/200\n","\n","Epoch 00158: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1173.6276 - val_loss: 1854.6427 - 3s/epoch - 8ms/step\n","Epoch 159/200\n","\n","Epoch 00159: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1169.2501 - val_loss: 1752.4821 - 3s/epoch - 7ms/step\n","Epoch 160/200\n","\n","Epoch 00160: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1133.7178 - val_loss: 1852.9103 - 3s/epoch - 8ms/step\n","Epoch 161/200\n","\n","Epoch 00161: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1140.5734 - val_loss: 1913.5034 - 3s/epoch - 7ms/step\n","Epoch 162/200\n","\n","Epoch 00162: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1148.4796 - val_loss: 1857.5902 - 3s/epoch - 8ms/step\n","Epoch 163/200\n","\n","Epoch 00163: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1109.1423 - val_loss: 1886.0448 - 3s/epoch - 7ms/step\n","Epoch 164/200\n","\n","Epoch 00164: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1112.5227 - val_loss: 1991.8186 - 3s/epoch - 7ms/step\n","Epoch 165/200\n","\n","Epoch 00165: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1112.0399 - val_loss: 1916.3650 - 3s/epoch - 8ms/step\n","Epoch 166/200\n","\n","Epoch 00166: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1162.5260 - val_loss: 1832.9584 - 3s/epoch - 7ms/step\n","Epoch 167/200\n","\n","Epoch 00167: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1163.0325 - val_loss: 1912.1820 - 3s/epoch - 7ms/step\n","Epoch 168/200\n","\n","Epoch 00168: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1114.1680 - val_loss: 1951.7728 - 3s/epoch - 7ms/step\n","Epoch 169/200\n","\n","Epoch 00169: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1087.3376 - val_loss: 2054.9473 - 3s/epoch - 7ms/step\n","Epoch 170/200\n","\n","Epoch 00170: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1119.3398 - val_loss: 1859.5162 - 3s/epoch - 7ms/step\n","Epoch 171/200\n","\n","Epoch 00171: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1098.5529 - val_loss: 2111.0061 - 3s/epoch - 7ms/step\n","Epoch 172/200\n","\n","Epoch 00172: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1124.1945 - val_loss: 1824.6116 - 3s/epoch - 7ms/step\n","Epoch 173/200\n","\n","Epoch 00173: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1080.4656 - val_loss: 1847.8843 - 3s/epoch - 8ms/step\n","Epoch 174/200\n","\n","Epoch 00174: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1085.6786 - val_loss: 1885.0647 - 3s/epoch - 7ms/step\n","Epoch 175/200\n","\n","Epoch 00175: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1086.5601 - val_loss: 1866.5286 - 3s/epoch - 7ms/step\n","Epoch 176/200\n","\n","Epoch 00176: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1057.2001 - val_loss: 1864.2991 - 3s/epoch - 7ms/step\n","Epoch 177/200\n","\n","Epoch 00177: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1061.1069 - val_loss: 1813.8833 - 3s/epoch - 7ms/step\n","Epoch 178/200\n","\n","Epoch 00178: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1062.8043 - val_loss: 1927.6033 - 3s/epoch - 7ms/step\n","Epoch 179/200\n","\n","Epoch 00179: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1047.2319 - val_loss: 1850.3035 - 3s/epoch - 7ms/step\n","Epoch 180/200\n","\n","Epoch 00180: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1042.7834 - val_loss: 1928.6711 - 3s/epoch - 7ms/step\n","Epoch 181/200\n","\n","Epoch 00181: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1039.1542 - val_loss: 2179.6047 - 3s/epoch - 7ms/step\n","Epoch 182/200\n","\n","Epoch 00182: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1047.0621 - val_loss: 1878.5902 - 3s/epoch - 7ms/step\n","Epoch 183/200\n","\n","Epoch 00183: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1018.9340 - val_loss: 2201.0125 - 3s/epoch - 7ms/step\n","Epoch 184/200\n","\n","Epoch 00184: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1046.7507 - val_loss: 1856.8079 - 3s/epoch - 7ms/step\n","Epoch 185/200\n","\n","Epoch 00185: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1016.0728 - val_loss: 1882.7405 - 3s/epoch - 7ms/step\n","Epoch 186/200\n","\n","Epoch 00186: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1033.4377 - val_loss: 1898.8243 - 3s/epoch - 8ms/step\n","Epoch 187/200\n","\n","Epoch 00187: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1067.0861 - val_loss: 1814.4534 - 3s/epoch - 8ms/step\n","Epoch 188/200\n","\n","Epoch 00188: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 996.7406 - val_loss: 1944.8164 - 3s/epoch - 7ms/step\n","Epoch 189/200\n","\n","Epoch 00189: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1016.2979 - val_loss: 2071.4856 - 3s/epoch - 8ms/step\n","Epoch 190/200\n","\n","Epoch 00190: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 983.2709 - val_loss: 1964.1772 - 3s/epoch - 7ms/step\n","Epoch 191/200\n","\n","Epoch 00191: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 992.1397 - val_loss: 2072.4165 - 3s/epoch - 7ms/step\n","Epoch 192/200\n","\n","Epoch 00192: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 999.4144 - val_loss: 1856.7710 - 3s/epoch - 7ms/step\n","Epoch 193/200\n","\n","Epoch 00193: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 962.3197 - val_loss: 2216.4534 - 3s/epoch - 7ms/step\n","Epoch 194/200\n","\n","Epoch 00194: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 967.4043 - val_loss: 1956.7617 - 3s/epoch - 7ms/step\n","Epoch 195/200\n","\n","Epoch 00195: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 1003.1688 - val_loss: 1936.9060 - 3s/epoch - 7ms/step\n","Epoch 196/200\n","\n","Epoch 00196: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 958.6409 - val_loss: 2284.7756 - 3s/epoch - 7ms/step\n","Epoch 197/200\n","\n","Epoch 00197: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 983.4426 - val_loss: 2019.1431 - 3s/epoch - 7ms/step\n","Epoch 198/200\n","\n","Epoch 00198: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 937.6448 - val_loss: 1891.5854 - 3s/epoch - 7ms/step\n","Epoch 199/200\n","\n","Epoch 00199: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 965.7117 - val_loss: 1866.2603 - 3s/epoch - 7ms/step\n","Epoch 200/200\n","\n","Epoch 00200: val_loss did not improve from 1696.06787\n","397/397 - 3s - loss: 963.2018 - val_loss: 1929.7175 - 3s/epoch - 7ms/step\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5dn48e89k30jCyGENWyiIAoIiEutu2JVbK2otRZbW7rYVm3rK11+r7baaldb26rFal+1KlJblbqhILgj+y5LWAIJCdlD9vX+/fGckMkkIYCZDML9ua655sxzlnnmzMy5z7Oc54iqYowxxhyML9wZMMYYc/SzYGGMMaZbFiyMMcZ0y4KFMcaYblmwMMYY0y0LFsYYY7plwcIYY0y3LFgY8wmJyC4RuTDc+TAmlCxYGGOM6ZYFC2NCQESiReSPIrLXe/xRRKK9eX1F5GURKReRUhF5V0R83rw7RSRPRCpFZIuIXBDeT2KMExHuDBhzjPopMBUYDyjwEvAz4P8BPwRygXRv2amAisho4LvAZFXdKyJZgL93s21M56xkYUxo3AD8QlULVbUI+DlwozevEcgEhqpqo6q+q26QtmYgGhgjIpGquktVt4cl98YEsWBhTGgMAHICXud4aQC/BbKBN0Rkh4jMBlDVbOA24G6gUETmisgAjDkKWLAwJjT2AkMDXg/x0lDVSlX9oaoOB64EftDaNqGqz6jq2d66Cvy6d7NtTOcsWBjTMyJFJKb1ATwL/ExE0kWkL/C/wD8BRORyERkpIgJU4KqfWkRktIic7zWE1wG1QEt4Po4x7VmwMKZnvIo7uLc+YoAVwDpgPbAKuNdbdhSwEKgCPgQeUtXFuPaK+4FioADoB/y49z6CMV0Tu/mRMcaY7ljJwhhjTLcsWBhjjOmWBQtjjDHdsmBhjDGmW8fkcB99+/bVrKyscGfDGGM+VVauXFmsqumdzTsmg0VWVhYrVqwIdzaMMeZTRURyuppn1VDGGGO6ZcHCGGNMtyxYGGOM6dYx2WZhjDFHorGxkdzcXOrq6sKdlZCKiYlh0KBBREZGHvI6FiyMMcaTm5tLYmIiWVlZuHEejz2qSklJCbm5uQwbNuyQ17NqKGOM8dTV1ZGWlnbMBgoAESEtLe2wS08WLIwxJsCxHChaHclntGARIL+ilt+/sYUdRVXhzooxxhxVLFgEKNxfz5/fymZncXW4s2KMOQ6Vl5fz0EMPHfZ6l112GeXl5SHIURsLFgH8Plc0a7FbfBhjwqCrYNHU1HTQ9V599VWSk5NDlS3AekO101qN12zRwhgTBrNnz2b79u2MHz+eyMhIYmJiSElJYfPmzWzdupWrrrqKPXv2UFdXx6233sqsWbOAtiGOqqqqmDZtGmeffTYffPABAwcO5KWXXiI2NvYT582CRYC2koUFC2OOdz//70Y27d3fo9scMyCJu64Y2+X8+++/nw0bNrBmzRqWLFnC5z73OTZs2HCgi+vjjz9OamoqtbW1TJ48mauvvpq0tLR229i2bRvPPvssjz76KDNmzODf//43X/7ylz9x3i1YBPCLBQtjzNFjypQp7a6FePDBB3nhhRcA2LNnD9u2besQLIYNG8b48eMBOO2009i1a1eP5MWCRYDW7mRWDWWMOVgJoLfEx8cfmF6yZAkLFy7kww8/JC4ujnPPPbfTayWio6MPTPv9fmpra3skL9bAHcCqoYwx4ZSYmEhlZWWn8yoqKkhJSSEuLo7NmzezdOnSXs1bSIOFiNwuIhtFZIOIPCsiMSIyTEQ+EpFsEXlORKK8ZaO919ne/KyA7fzYS98iIpeEKr/+AyWLUL2DMcZ0LS0tjbPOOouTTz6ZO+64o928Sy+9lKamJk466SRmz57N1KlTezVvIauGEpGBwPeBMapaKyLzgOuAy4AHVHWuiDwC3Aw87D2XqepIEbkO+DVwrYiM8dYbCwwAForICara3NN59nmh00oWxphweeaZZzpNj46O5rXXXut0Xmu7RN++fdmwYcOB9B/96Ec9lq9QV0NFALEiEgHEAfnA+cDz3vwngKu86enea7z5F4hrRJgOzFXVelXdCWQDU0KRWV9rA7e1WRhjTDshCxaqmgf8DtiNCxIVwEqgXFVbrzDJBQZ60wOBPd66Td7yaYHpnaxzgIjMEpEVIrKiqKjoiPLc2mbRbCULY4xpJ2TBQkRScKWCYbjqo3jg0lC9n6rOUdVJqjopPb3T+41360DJwmKFMca0E8pqqAuBnapapKqNwH+As4Bkr1oKYBCQ503nAYMBvPl9gJLA9E7W6VFewcKqoYwxJkgog8VuYKqIxHltDxcAm4DFwBe9ZWYCL3nT873XePPfUlX10q/zeksNA0YBy0KR4QPVUBYsjDGmnZD1hlLVj0TkeWAV0ASsBuYArwBzReReL+0xb5XHgKdEJBsoxfWAQlU3ej2pNnnbuSUUPaEAfHadhTHGdCqkV3Cr6l3AXUHJO+ikN5Oq1gHXdLGdXwK/7PEMBrHhPowxnyYJCQlUVfXO/XfsCu4APrsozxhjOmVjQwWwi/KMMeE0e/ZsBg8ezC233ALA3XffTUREBIsXL6asrIzGxkbuvfdepk+f3ut5s2ARwG8X5RljWr02GwrW9+w2+4+Dafd3Ofvaa6/ltttuOxAs5s2bx4IFC/j+979PUlISxcXFTJ06lSuvvLLX7xVuwSKAXZRnjAmnCRMmUFhYyN69eykqKiIlJYX+/ftz++2388477+Dz+cjLy2Pfvn3079+/V/NmwSKAWMnCGNPqICWAULrmmmt4/vnnKSgo4Nprr+Xpp5+mqKiIlStXEhkZSVZWVqdDk4eaBYsgfp9YycIYEzbXXnst3/jGNyguLubtt99m3rx59OvXj8jISBYvXkxOTk5Y8mXBIohfxIb7MMaEzdixY6msrGTgwIFkZmZyww03cMUVVzBu3DgmTZrEiSeeGJZ8WbAIImLVUMaY8Fq/vq1hvW/fvnz44YedLtdb11iAXWfRgd8nNtyHMcYEsWARxKqhjDGmIwsWQXw+sYvyjDmO6XHw/z+Sz2jBIohPbNRZY45XMTExlJSUHNMBQ1UpKSkhJibmsNazBu4g1nXWmOPXoEGDyM3N5UjvtvlpERMTw6BBgw5rHQsWQXwix/RZhTGma5GRkQwbNizc2TgqWTVUEJ9YbyhjjAlmwSKI6zob7lwYY8zRxYJFEJ/v+OgNYYwxh8OCRRC/WAO3McYEC1mwEJHRIrIm4LFfRG4TkVQReVNEtnnPKd7yIiIPiki2iKwTkYkB25rpLb9NRGaGKs9gbRbGGNOZkAULVd2iquNVdTxwGlADvADMBhap6ihgkfcaYBowynvMAh4GEJFU3H28T8fdu/uu1gATCnZRnjHGdNRb1VAXANtVNQeYDjzhpT8BXOVNTweeVGcpkCwimcAlwJuqWqqqZcCbwKWhyqhfhBZr4DbGmHZ6K1hcBzzrTWeoar43XQBkeNMDgT0B6+R6aV2ltyMis0RkhYis+CQX1IjYnfKMMSZYyIOFiEQBVwL/Cp6nrttRjxyZVXWOqk5S1Unp6elHvB2/T2yIcmOMCdIbJYtpwCpV3ee93udVL+E9F3rpecDggPUGeWldpYeE39osjDGmg94IFtfTVgUFMB9o7dE0E3gpIP0rXq+oqUCFV121ALhYRFK8hu2LvbSQ8InQbLHCGGPaCenYUCISD1wEfDMg+X5gnojcDOQAM7z0V4HLgGxcz6mvAqhqqYjcAyz3lvuFqpaGKs8+u1OeMcZ0ENJgoarVQFpQWgmud1Twsgrc0sV2HgceD0Ueg9md8owxpiO7gjuIT6zNwhhjglmwCGLBwhhjOrJgEcSqoYwxpiMLFkHccB/hzoUxxhxdLFgE8QtWDWWMMUEsWASxUWeNMaYjCxZBfNZmYYwxHViwCOIXwWqhjDGmPQsWQXw+G3XWGGOCWbAI4hMbddYYY4JZsAhio84aY0xHFiyC+EWsGsoYY4JYsAgidltVY4zpwIJFEL8P6zprjDFBLFgEsTYLY4zpyIJFEBt11hhjOrJgEcSG+zDGmI5CGixEJFlEnheRzSLysYicISKpIvKmiGzznlO8ZUVEHhSRbBFZJyITA7Yz01t+m4jM7PodPzm/jTprjDEdhLpk8SfgdVU9ETgV+BiYDSxS1VHAIu81wDRglPeYBTwMICKpwF3A6cAU4K7WABMKdlGeMcZ0FLJgISJ9gHOAxwBUtUFVy4HpwBPeYk8AV3nT04En1VkKJItIJnAJ8KaqlqpqGfAmcGmo8u0TG+7DGGOChbJkMQwoAv4hIqtF5O8iEg9kqGq+t0wBkOFNDwT2BKyf66V1ld6OiMwSkRUisqKoqOiIM229oYwxpqNQBosIYCLwsKpOAKppq3ICQFUV6JEjs6rOUdVJqjopPT39iLfj89lFecYYEyyUwSIXyFXVj7zXz+OCxz6vegnvudCbnwcMDlh/kJfWVXpI2HAfxhjTUciChaoWAHtEZLSXdAGwCZgPtPZomgm85E3PB77i9YqaClR41VULgItFJMVr2L7YSwsJn9gV3MYYEywixNv/HvC0iEQBO4Cv4gLUPBG5GcgBZnjLvgpcBmQDNd6yqGqpiNwDLPeW+4WqloYqwz6f4L0vIhKqtzHGmE+VkAYLVV0DTOpk1gWdLKvALV1s53Hg8Z7NXef8XoBoblEi/BYsjDEG7AruDlpLFtZuYYwxbSxYBPFJazVUmDNijDFHEQsWQfzeHrFGbmOMaWPBIkhrycKqoYwxpo0FiyCtwcLGhzLGmDYWLIL4vQZuixXGGNPGgkWQA72hLFoYY8wBFiyCeLHCBhM0xpgAFiyCtF6UZ8HCGGPaWLAIYtVQxhjTkQWLIAdKFjZMuTHGHGDBIoiv9aI8q4YyxpgDLFgE8VmbhTHGdGDBIsiB6yyszcIYYw6wYBHEhvswxpiOLFgE8VkDtzHGdGDBIkjbcB9WsjDGmFYWLILYEOXGGNNRSIOFiOwSkfUiskZEVnhpqSLypohs855TvHQRkQdFJFtE1onIxIDtzPSW3yYiM0OcZ8DaLIwxJlBvlCzOU9Xxqtp6L+7ZwCJVHQUs8l4DTANGeY9ZwMPgggtwF3A6MAW4qzXAhIL/wJ3yLFgYY0yrcFRDTQee8KafAK4KSH9SnaVAsohkApcAb6pqqaqWAW8Cl4Yqc/4Dw32E6h2MMebTJ9TBQoE3RGSliMzy0jJUNd+bLgAyvOmBwJ6AdXO9tK7S2xGRWSKyQkRWFBUVHXGGvYKFtVkYY0yAiENZSETigVpVbRGRE4ATgddUtbGbVc9W1TwR6Qe8KSKbA2eqqopIjxyVVXUOMAdg0qRJR7xNq4YyxpiODrVk8Q4QIyIDgTeAG4H/624lVc3znguBF3BtDvu86iW850Jv8TxgcMDqg7y0rtJD4kA1lAULY4w54FCDhahqDfAF4CFVvQYYe9AVROJFJLF1GrgY2ADMB1p7NM0EXvKm5wNf8XpFTQUqvOqqBcDFIpLiNWxf7KWFhA1RbowxHR1SNRSuZ+sZwA3AzV6av5t1MoAXvK6oEcAzqvq6iCwH5onIzUAOMMNb/lXgMiAbqAG+CqCqpSJyD7DcW+4Xqlp6iPk+bDaQoDHGdHSoweI24MfAC6q6UUSGA4sPtoKq7gBO7SS9BLigk3QFbuliW48Djx9iXj8Ru5+FMcZ0dEjBQlXfBt4GEBEfUKyq3w9lxsLF7mdhjDEdHVKbhYg8IyJJXtvDBmCTiNwR2qyFhw1RbowxHR1qA/cYVd2Pu4DuNWAYrkfUMaetzSLMGTHGmKPIoQaLSBGJxAWL+d71Fcfk4dTuZ2GMMR0darD4G7ALiAfeEZGhwP5QZSqcrBrKGGM6OtQG7geBBwOSckTkvNBkKbx8NtyHMcZ0cKgN3H1E5A+tYy+JyO9xpYxjjl1nYYwxHR1qNdTjQCXuAroZuCqof4QqU+Fkd8ozxpiODvWivBGqenXA65+LyJpQZCjcbIhyY4zp6FBLFrUicnbrCxE5C6gNTZbCq3WIcitZGGNMm0MtWXwLeFJE+nivy2gbDPCY4rc2C2OM6eBQe0OtBU4VkSTv9X4RuQ1YF8rMhYPfRp01xpgODutOeaq637uSG+AHIchP2IlYsDDGmGCf5Laq0mO5OIq0liysFsoYY9p8kmBxTB5O/TbchzHGdHDQNgsRqaTzoCBAbEhyFGYHhii3aihjjDngoMFCVRN7KyNHi9YruNVKFsYYc8AnqYY6JCLiF5HVIvKy93qYiHwkItki8pyIRHnp0d7rbG9+VsA2fuylbxGRS0KZ3wPVUHZRnjHGHBDyYAHcCnwc8PrXwAOqOhJ3vUbrPb1vBsq89Ae85RCRMcB1wFjgUuAhEenu/t9HzOezNgtjjAkW0mAhIoOAzwF/914LcD7wvLfIE7h7ZABM917jzb/AW346MFdV61V1J5ANTAllvn1iQ5QbY0ygUJcs/gj8D9BaqZMGlKtqk/c6FxjoTQ8E9gB48yu85Q+kd7JOSPh9YldwG2NMgJAFCxG5HChU1ZWheo+g95vVOoR6UVHRJ9qWT8SqoYwxJkAoSxZnAVeKyC5gLq766U9Asoi09sIaBOR503nAYABvfh+gJDC9k3UOUNU5qjpJVSelp6d/ooz7fWLVUMYYEyBkwUJVf6yqg1Q1C9dA/Zaq3gAsBr7oLTYTeMmbnk/b4IRf9JZXL/06r7fUMGAUsCxU+QZXsrBYYYwxbQ511NmedCcwV0TuBVYDj3npjwFPiUg2UIoLMKjqRhGZB2wCmoBbVLU5lBn0iV2UZ4wxgXolWKjqEmCJN72DTnozqWodcE0X6/8S+GXoctieNXAbY0x7vXGdxaeOT8RKFsYYE8CCRSd8PmuzMMaYQBYsOuEX6w1ljDGBLFh0wu+z6yyMMSaQBYtOiNg9uI0xJpAFi07YRXnGGNOeBYtO+EVotlhhjDEHWLDohM+uszDGmHYsWHTChig3xpj2LFh0wi7KM8aY9ixYdMKG+zDGmPYsWHTCRp01xpj2LFh0wuezaihjjAlkwaITfrsozxhj2rFg0QlrszDGmPYsWHRCrDeUMca0Y8GiE27U2XDnwhhjjh4WLDpho84aY0x7IQsWIhIjIstEZK2IbBSRn3vpw0TkIxHJFpHnRCTKS4/2Xmd787MCtvVjL32LiFwSqjy3vZ81cBtjTKBQlizqgfNV9VRgPHCpiEwFfg08oKojgTLgZm/5m4EyL/0BbzlEZAxwHTAWuBR4SET8Icy3jTprjDFBQhYs1KnyXkZ6DwXOB5730p8ArvKmp3uv8eZfICLipc9V1XpV3QlkA1NCkun8dfDI2ZxQ/7FVQxljTICQtlmIiF9E1gCFwJvAdqBcVZu8RXKBgd70QGAPgDe/AkgLTO9kncD3miUiK0RkRVFR0ZFlOCoeCtaT2bzHGriNMSZASIOFqjar6nhgEK40cGII32uOqk5S1Unp6elHtpE+g0F8ZDQXUNvY3LMZNMaYT7Fe6Q2lquXAYuAMIFlEIrxZg4A8bzoPGAzgze8DlASmd7JOz4qIgqRBZEkhe0praGy24oUxxkBoe0Oli0iyNx0LXAR8jAsaX/QWmwm85E3P917jzX9LVdVLv87rLTUMGAUsC1W+Sc0io6WAphYlp6Q6ZG9jjDGfJhHdL3LEMoEnvJ5LPmCeqr4sIpuAuSJyL7AaeMxb/jHgKRHJBkpxPaBQ1Y0iMg/YBDQBt6hq6OqIUrJIyn8VgOzCKkb2SwzZWxljzKdFyIKFqq4DJnSSvoNOejOpah1wTRfb+iXwy57OY6dShhFZV0w8tWQXVnW/vDHGHAfsCu5gKVkATEyssGBhjDEeCxbBUocBcFqf/WQXWbAwxhiwYNGRV7IYE1PC9sJqu5LbGGOwYNFRbArEJJPlK6S2sZm9FbXhzpExxoSdBYvOpGTRrykfgG3WbmGMMRYsOpU6nKTqHCJ8wkc7SsOdG2OMCTsLFp3JGIOvIodzhkSzeHNhuHNjjDFhZ8GiMxnjAJg+sIIt+yrJLasJc4aMMSa8LFh0JmMsAGfEFwBY6cIYc9yzYNGZPoMgug/p1dsYmhbHIgsWxpjjnAWLzohAxlikcCOXntyfd7cVs8Mu0DPGHMcsWHSl/8mwbxNfPyuLKL+PPy3aFu4cGWNM2Fiw6ErGWGioJL2pgJvOymL+2r28tCaP+ia7KZIxJsyW/x0K1vfqW1qw6ErGye45fw3fPGc4WSkx5D//P6z41UVk76sMb96MMbBtIax+Oty56H0N1fDKj+CDP/fq21qw6ErmqRCfDuufJzk2kkWjnudbES9zVstK7vjbv3ljY4GNG2VMOH3wICz6ebhzcWgKNkD5niNbd+sb8PIP2l4XbwUUcpf3SNYOlQWLrvgjYfyXYMtr8N4f8K19BibcCMB5ERuY9dRKLvnjOzz+3k7ybfwo01uWPeoOPAbKd0PVPqirCHdOOvfq/8CG/7jpudfDgh8f2XbWzYUVj0HlPve6cLN7Lt0BNb03woQFi4OZ8BXQZlj0Cxg8Fa54EFKy+O7QPfxhxqnERfm5/+W1nHnfQj7728Xc+fw6/rViDzuKqnB3hDUdNDdCdUm4c/Hp1FgLr/4Ils0Jd07Cr6UZKnLddHF2ePPSmdoyWPY3WP1PN12++8iDfNFW99xakija3DYvd8Uny+dhsGBxMH1HwpAzwRcBV/wRfD4Yfh6+nPf5wqkZvHTzyWxKvYPnx3zA6IxEXt9YwB3Pr+P837/NxHve5CuPL+P+1zbzQXYxJVX1VNc3hfsThd9Hj8CfJ0JTw6Etvz8fnv2SBRiAshz3XHIUHhx7W2U+tDS66ZIQ9VQs3w2/Pwny1x7+unu8A3vBOti30U2X7XIB/3C0NLd9vtxl7rloCyQPBfFBXu8Fi5DdVlVEBgNPAhmAAnNU9U8ikgo8B2QBu4AZqlomIgL8CbgMqAFuUtVV3rZmAj/zNn2vqj4Rqnx3MP0v7gym30nu9YjzYOU/XETfsYSImkJOK3qBObffSws+thdVsTKnjFW7y9i4dz+PvbeDR97efmBzafFRjEhPYES/eEakJzBuYB8mZaXi90mvfaSwylsJdeXuj5N+QvfLb/wPbHkFdnwBxn3x4Mu2tLiSoD+yR7J61Cnb6Z6LOzk4VhVBZAxEHyf3jG8NnND5/jhSDTWw5mmY+BXY/hZU7oXsRa4N83Ds+cg9Vxe59QFQ197Q1bYW3u1KEdc9DUvugz3L4PIHoKnO22ZryeJjGHia+657sWQRsmABNAE/VNVVIpIIrBSRN4GbgEWqer+IzAZmA3cC04BR3uN04GHgdC+43AVMwgWdlSIyX1XLQpj3Nmkj3KPVsHPAHw0v3w778yBxgPtBbX8LX/IQRiWmM2rKEK6bMgSA6vomPthewt7yWqobmsgprmFHcRULNu6jtNo1eCXHRSJAUmwk104ezLWTBpOWEE1Li+ILCiK1Dc38c2kOE4YkMykrtet8N3tnXf5IV6/Z3ACJ/b163kIYNKkn99Kha/1jl2w7tGCxY4l7Lvy4+2Xf+4Mr9n9/tbuw8lhT6gWL6kJXTx/Tp23ek9PdtUFfOE6qqMp3u+eImJ4tWbz7O3j3927f7vHO5PeuPvzt7PkIImKhqRbWPQcIoK69obNgUVUIH/7V/U+XPgTv/sGVnLa/5eYPmOjyUbffBcpTv+SCxaYX3UmSL/SVRCELFqqaD+R705Ui8jEwEJgOnOst9gSwBBcspgNPqqvsXyoiySKS6S37pqqWAngB51Lg2VDl/aBiU+BLc+HfX4f6/TBzPvzzanj1DijPgaSB8KV5ridVbArx0RFcNCaj002VVjfwwfZi3t5SRHSkj+zCKn7z+hb+uHAbI9MT2Lqvkqy+8UzOSqWpuYWaxmZW55Sxt6KOmEgf//fVKUwdntZ5Pp/7MjTVw1dedHkt3w3fXe4a3XZ/AHfsAH8ozxU60dLcVoVSvBX4nJte+xz0O7Hjn6ipAXa976YPJVhsf8udfe/fC30G9li2Q6q6GOL7HtqyrSULcPX0g05z0w01ULjJ/R67UlsOsclHns+jTXkOIDDkjMNrs1CF+d+DgRNh0tfaz6vIdQdsgK0L2oJE/prDy1tzozvjH3e169q7P8+1eeatdKWCzix71K2XNAgW/MRVMbWmA0y4AV75IWx8AVBIH+1OYlc94X73oy48vDwegV5psxCRLGAC8BGQ4QUSgAJcNRW4QBLYtyzXS+sqPfg9ZonIChFZUVRU1KP572DE+fCt9+GmV2HABDjlWvdHHnmROzN4+Az43Uj462TY/Iqr89y7GvZtcj/Wne/CX6eS+tFvuHxULL+95lTuvWocc2edwZu3n8N1kweTEh/JzDOz6JcYzesb8nkvu5iP8/czLD2eR78yicEpccx8fBn/78UNvLY+n4Wb9rF6dxmVdY1Qsh22vg47FvPR4vno9rfc2Vf+WnemXlcBBQeph21qCE2Pm4o9bUXq1j94fRW89B1YfF/H5XOXQ2O1O8sr3HTwbbc0w17vT93dskeLvWvgd6PaSk/dKd0JUV41U+DZdGtXyoo9bT1mgt/nN8Nh++JPmuPw2PU+5K5sn1a+GxIz3cWzJdnu+z8Um16E1U+5A+/Od9rS6yrgv7e6/+fwc93/p3Q7JHil8e56Ham2tUcUrHMlihEXQOpwl5Z5KqSNbOvJFKihxl1kN3oaTLvfpZ1xC8T3c8ElPh1GXeLSl3jz00+Ek650++CDB9u2VbAhZO17IT+1FJEE4N/Abaq6XwKqB1RVRaRHug2p6hxgDsCkSZNC3xUpKdM9AM77KQw/D0Zd5M5O1s11xeMVj8PcL7Vfr98YdzCPToR3fgvLH4OL74GxX4CoOEZlJPKL6Se3fih4/48QuQhmPAkNVbDrPTjpdMYPTubXr2/mueV7eGppW/1tVISPv6T9hwvED6oMWXIrrbs4+5+3MrLJ/aDzVr9BZubEDtVcALx+p8v7zW/C4Ckd5298wR20DvdsprUKKirBO8ABe5ZCS5Mr7bQ0g8/ftvyOxe4Ma8KN7oyvoRqi4rvY9lYXWMA1KI666PDy1pn3/+TaVi5/4JNvqzObXgRtgeyF7gDVnbKdMDDhzxMAABzvSURBVOwz7qy3eBu8dAsMO9ftv1Z7V7mDTqBVT7q2nI3/cW1ugSoL3EGpF6oxjsiOJa7kLj645gk48TKXXpYDyUOg7yhorneBMiWr4/qbX4XNL8Ol97lqoYU/dwdabYHnvwbf/sAFiqc+70oAl/4aEvq1BfDJN8PiX7qTvZEXdJ3Pd34LH/4Fbl7oSsoAQ6ZC5iku6GSMdd18W0spZTnupGbUxe54UVsKZ3wXhp4JX30NBk5ygX/9POg72g1ueuHd8NHfIK6vK1X4I+H0b8HCuyB/nftvPDkdBoyHL/+7R3Z/oJAGCxGJxAWKp1XV63DMPhHJVNV8r5qpdUjXPGBwwOqDvLQ82qqtWtOXhDLfhy06AU642E0nD4Zz7nDTk78BO992f2bxueqRZY+6IvB1z7gf+Kt3uD/9/O9B6gjIGOMCjS/C/Yg3v+y29ex17gynMh+qCkk/+zZ+d0k695f9kKrELHafdR9F1S18tHk3k9e+zoLm00iNaGAqa9jASGhp4uSaNdQRxT5NYedHrzFtxURG909EECYMTebSsf0Z4SsgceUTCND0+s+I+PqC9vX/tWXw4nfcD/bWte0PMu/81p0BfvYO1wAXrGiLex55ofszqrad3dVVuIN85ilty2cvdNsZMtX9EYs2d75dcEV8AH9Uz5QsWlrgg7+49oGzbu38QBSoYL37LOJzf+BDaTPZ/Kp7zvnQVUc99XkXmDprT2ppdgeYEy93+3HtXNif66aHngm+SHcAzFvZPlg01cMG78CxdUH7+u2irfDwmXDSFXD1Y70fMBpq3PUHUQnuoDzi/Pbz89fCczdC3xMgMhbm3QhX/x3Gft5VQw09E9JGuWX3bXLfUVWRq9YTcZ933o3u/1e4yZVQy3bCl/7lDr5zzoWXvuv+l4018LU3YPBk91v0RbjvcuLMtmCROtx1XS7Y4E6UkrNc9emQM+C9P7qTlac+776Xyd+ApAHQ/xR3cpVxsvvvbnoJ/nZOWw+rc3/iAkLmePd5RNwzuBOI9fNc254InH07nHmrq71o7cRx2k3wzu/gySvdcQN1AS8EQtkbSoDHgI9V9Q8Bs+YDM4H7veeXAtK/KyJzcQ3cFV5AWQD8SkRSvOUuBo7w6pZeFhkDJ1zSPm3yzW3Tcanw1dch+03IWwX7NrgfYkuTe9RVuANV+onw4rfdGeCI891Vq6XbIfstImqKSd67nOTGIohP54JtbwD7Oe/LPyaqrgRe+DojLryZuopCWP4AMSecT//4AQxc9yx/6/MMg4pXcU/yvbz/3hoS3/+QRt9mxkoEjzR9nh/mPc/fH/4t6WfeQHZhFbFRfs7a9wynNtZAxW6qtn9Awqiz3WfJ+RDe+qUrGWx9zZ0FnX17+89evBXi0mDw6e6suqbEVcmlDHN/4pz324JF8Tb3B73oHlcaA9duERwsmhq8LoSrIDrJHWhbuyp+EnkrXKAAWPMMnPeTrpfdvxcePd/9iQH6j4Osszs2Qgcq2Q7FW9x3mr8GVvzDVV+serLzYLE/zzV4pg5zZ9NbX/fyudId2Pqe4O2HoOqaLa+53menXOfOYPeubmvrWPqQ+51t/I/rtdPSBEPPgjFXuirAoWe19QIM1NzkGnAHTYaIqPbzira4zyACZ90OEdGu9OKPdCWBwCD61j3upCGurzsp+sZbbd9v/jp3lhzTB274l/tun5nhSgPVxW5/JA9x1TsJ/eG1O6Fwo/sNnvcTOPU6mDfTndGf8T1X1RmdCJfc50qdInDhXa59AFw74+DJbjqmjzuhaaqDxAwXJJbNgbd/405Ghn8WNs1vayNKG+WqnS65z114lzEOLr7XzTvlWvc7yDzV/d5RaKyDS34FOR/Akl+55a5+rOMJxojz3ElA5vi2NJ8PfDFtr2OT4ab/uoCRu9ztq74jO35nPSCUJYuzgBuB9SLS2kL0E1yQmCciNwM5wAxv3qu4brPZuK6zXwVQ1VIRuQdovbb9F62N3ccEn88FlOCgEiyurzuLiU2Bp2fAx/91jWHXP+N+dAvvdsuMuhgm3Uzs0DPcn7qlntiTv0hs8RZY/gCMnkZ0bAqsfpwzSl8EXyRzGn+KxhRCcwOC8vGY2zh74nfI/88Gbiq8jz/8axurOJHilgSujHqCj/2jyGrOYcHcP/O3hGYGRFbxQPVsYuIH8vG05xm47B4yFt6N7t+LjLvGFal9PhcA+p7gHuAObPlr4DM/cj1GdrztDlrpJ7qDjvhg3DWuWiAipq2Re3++C0jbFrqSW2Scm595qjtQf/iQayzsrgtt0RY3vs4Fd0FCevt5m192B+GBp7lGys/e2b6KLNDSh92Bdtbb7gC3/O+ugXPRL+D6Zzv/brd4pYpzZ8MrP3A9ucAFgc56t7T2hEoZ5uq+AUZf5raz+0M4+Wp3hr7xRZh7gztIn3q9OytOzIRLfunOUre86oJFdQmsfRYmfNn1klv9tDswvvs79wC3Ty+6x+3T6ERIyHBn7S/f5ur9EzPdWX7GyS6orJ3rLkRrLeUsf8wdcLXFbW/khXDFn9yBf91zbr9N/gZc8L/w4Hh461648QV3AjH3BohJgpn/daUAcFUrc29wZ/fgrjWITnD7+B+XufVj+rieRDkfAArXPu1K+0PPdAfWwGrM07/tTs7SRnT8jq75P1fyBVfFvG6e21ef+WFb54mmBlcFtPQhGDcDzviOO9npe4I7UQS37EXekCSjLoLvrnA1CD6f+35yl7v9NWZ6x99I0gD4/irX4/JgBkxw3W1DTI7FK40nTZqkK1b0Xv/jo8KhdJ/LW+UOqHUV8NBU92M94RJXJzxkKnzh7+4P1XpQrK+k+d/fxL/1lXabab7mScqWzyMq5x3e7nMl51W8QFRLHTMbZ/Nhy1h8tPCriL9zXcQSADb4RvMUV/CT5od5N/JMVgz+GnfvvJ7afhOILVzNhgv/yeh9LxO5fi4AKj4kOslV1934gnvTv53jDphpI71eKgp9hrh65O2LXBXdWbdCv7HwwixXF506ou1PG6xuPzx6nmscHX6e2xdL7oOxV7k2kmdmuDPXCTfC8191B4mBk2D5o+5M74RLXNVG0iB3tjvqIrjmH7Dgp+7CQ/G5g2RELHzxcYiKc20gyUNcG9ej57kD8E2vwP1D3ecZcoY78H9tgeu2uX2Ra6cZc5XL58p/wG3r3TAPi38F18+FB0521R/n/cwd9Od/F2KSXbBsrHaNo1+Y40qk/7jMld7i+rpAWpkP31navvRQsMHt3/7j3GfJea/9fus/zlW5jf+y6zKe86E7q2415ZuuGram2B1EE/q7klD5bnf2G7jswEmuN2FUvAvab/zMBcBtb7oD+A3/cvsr+He+fp7rIn3VQ23zdyxxeT/xMvjr6a6U99k7D14iPFQtLe677Kr34M533f8qJunwt12R6040uqvm7CUislJVO+1Xb8HieBXYmFxf5f6wndWzq7oz+qp9rhit6s5it78FT18NCAz/LPvP+xXbdQDV9c1ER/rYXljF3rw99M9fyBUlj5PYXA7Akxl38vt9E1isXydVqvi4ZTBXNdzDZbEb+Z3+gXuabuT6iLcZzU4qLv0rCVNuoK6xmVdfepYxhS9zYmwF/uHnuA4B6aNdnisLXJXGWbe5M9lHzoboPu7ANOFGV99dku26NQ+a7A4wS+5zZ5+nzXSN+eD+sGU5uMt5gMt+5+qsX/imq6oBd3ZdVdi2TKtZS9wZXsl2d4V6XBp8+T/wzLVQ5W7PS3SSq7qI6+sC9k0vuyD9yNmul8x3l8FfJruz45oSV53h87XVbycOgNs3tC/hPD0Dti2Aa//peuOte861QTTVu6q+cTMg3uteXbIdPp7vGu1ry1z13rmzD/4byV/rqrHqK93vYM0zLs9XPeLy1tLsgvi+DW6/DpzY9faKs13JprnBnekPOaPtN9dY6w7y9ZVw4udcp4/YlK63dTDvPeDaab62oOsOEaZTFixMaBRtcQfg6ISDL1db7torUoZBQjrlNQ288O4q4mOjGTdqBPv21/HUhzms2VnAZROGsWPHNsaVvM7jzdOQiGhiIv1U1LqLDPsnxeATqKhtJCEmgmknZ3LxmAxKqhvYt7+O5sYGblx5Nb7EDDRtFNGbngefH1/aSNfw2DroXHSSq5qZcKOrLkLdGX/ZLti91B1MJ9/cdrDZ+Y5rmxj7BdcxoXCTO9gWfuwaR0+Z0fZ5lz7s5g3/rNtO7krX22X0Za6b49u/dg3Zrf38N813Z/mnfxOeuNJVrV1wF3zGG2m0bJd7Tsx01UuBlj3qqmW+v8a1Z3yaNdW7qr+uqvsOh+qxeWFmiFmwMJ8qDU0tvL21iH3768gpqaZgfz0zzxhKY7PyyNvbSY2PIjU+ioKKOhZsLKDpIEPF96GKOqLol9qH0qp6JkXt4azkUgZM+TwJfVLYU1pDVt94xg9OJjGml4YJOdiFeMXb3KO1i2h3mhvddRStjbPGfAIWLMwxq6CijuzCKvolRZPhlTq2F1WTXVjF/tpGTspMYl1uOWtzy8lIiqGitpFlO0vJLWs/oFtMpI9Lx/ZnyrA0fAI7iqtJiYtiUEosg1JiyUiKoV9iNBH+o/R6BGN6gAULYwK0tCgrd5fR1KwMTYtjZ3E1r67P55X1+ZTXuOquKL+PhuaWdutFR/g4KTOJAckxJMdF0Sc2kn0VdRRV1RMfFcEpg/vwuXGZDE2LZ11uOa9tKOBbnx1Bn9hjdGBDc8yxYGHMIVBV9pTW0qLKkNQ4ahqbyS2rIbe0lsLKenYUVbFhbwVFlfWU1zRSXttIekI0GX1iqKxrZEeRu4J84pBk1uVW0NSinJCRwJenDiW3rJaE6AhOyEjg7FHpJES7njWNzS1EWmnFHCUsWBgTAqpK4PA1eeW1vLg6jxdW5zEmM4nLxmVyx7/WUlnf1K6kEuX3MXVEGk3NLSzdUUJyXBQj0uMZ2S+Bc0f3Y8LgZPbtr2dtbjkxkX6unjiw3ftU1zexp6yGE/sfQVdNYw7CgoUxYVJR00hVQxMD+sTQ0NzC6t3lLNy0j7c2F4LAhSdlUFnXyPaiarYUVB7o9RXoi6cN4uQBSWwuqEREeH1DPmU1jXz97GF857yRxEb6iY3yU17TwNZ9VZwyqA8xkT3Qo8gcdyxYGPMp0NTcwvvbS8gpqaZfYjQnZSbxn1V5/GmRG4AxLT6KhuYWpmSlkp4YzdzlbYMxp8ZHUV7TQItCbKSf04amMKxvvHukxzMkNY7mFmV3ibufyrSTMxmcGheuj2qOUhYsjPkUW7unnMSYCIant7+e5b1txWQXVlLd0Mye0hrSE6MZk5nE+9uLWZ+3nx1FVVTWdX4r37goP1+aMoToSB9xURGkJ7jgNGZA0vFz10bTgQULY45DqkpJdQM7i6vZU1pDVISP/kkxpMRHcc/Lm3h7axECBF6mMrJfAhec1I/VOeWMzEjg8lMyySur5fUNBWzK388fZoznjBEdb7i1bV8lAKMyjpPbuh6jLFgYY7pU19hMQUUdK3PKmPPODrYWVjImM4lthVU0NLlG+f5JMURF+CioqOOisRnUNjQTHeEjNspPaXUDS7a4G459fsJAxg5IIjrST1KMu0tkXFQv35HRHDELFsaYQ9LSotQ1NRMXFUFxVT1r95QzNC2OYX0TqKxr5Afz1rK9qIqE6Ajqm1qobXB3qPviaYOoa2rmH+/vOhBgAE4dnMyjN55GsyrFlQ34fHBS/yRqG5vZX9dIZp/YcH1U0wkLFsaYXtHY3EJtYzN1jc0s21nKD+etpb6p/cWNSTERVDc009yiTBiSzKShKcRGRVBQUUt8dASj+iVyzgl9iY+KoLCynhHp8UT4fR26Kpued7BgYeVDY0yPifT7iPT7SIqJ5PJTBjA0NZ63txaSGh9N34QoquqbWLqjhIykGGKj/Ly8Np+nluZQ19hCemI01fVN1DS0v592UkwEiTGRFOyvY0xmEued2I/LT8mkuLKedXkVbN1XyYn9EzltaAp9E6JJS4gmPspvgaWHWcnCGBNWqkpzix4oPewormbJliJaWpTU+Cg+2llCfVML/RKjWbOnnBU5ZQQetvomRFNcVd9umwOTY/l/l5/EqIxE9pTWUFBRx9ThaWT1bRuyvKahibvnb2RdbgWJMRH87+VjGTeoizsbHiesGsoYc8zYW17Lki1FDEqJ5ZRBfUiOiyK/opbN+ZWUVDdQXFXPi6vz2FxQ2W69mEgf3zxnBKnxUTQ0tfDyur2sz6vg3NH92LR3PxW1jfx8+limndyfZ5ftprymkTNGpPHahgIifcKPLhndeyMTh0lYgoWIPA5cDhSq6sleWirwHJAF7AJmqGqZd7/uP+Fuq1oD3KSqq7x1ZgI/8zZ7r6o+0d17W7Aw5vjW1NzCK+vzaW5RBqfGkRQTyX2vfXyg1xZAQnQED1w7novGZFBYWce3nlrJqt3l+H1Cc4seeI6O8NHUogxMjmVY33gq69xV9heP7c/1k4fQrEp1fRNRET4ykrq4M2MX9u2vQ4B+h7leqIQrWJwDVAFPBgSL3wClqnq/iMwGUlT1ThG5DPgeLlicDvxJVU/3gssKYBLu1mQrgdNUtexg723BwhgTrPW6E58IkX4hNtLfbsj5lhZl0eZC3tpcyOcnDGREejzLd5UyZVga2YVV3PvKJgCSYiKpqm9izZ7yDu8xrG88w/vG0ycukj6xkVTUNFLT0My1UwZTWtXAe9nFfGHiQIanJ/Dcst387Z0dJMZE8t/vnXVU9AwLWzWUiGQBLwcEiy3AuaqaLyKZwBJVHS0if/Omnw1crvWhqt/00tst1xULFsaYUFuZU8pHO0uJi/QTFx3B/tpGlu4oIb+ijvKaRipqG0mMiaCpRSmqdG0q0RG+dr3Dpp3cn3e2FjEwJZakmEh8PuH2C08gOS6SnJJq8ivquPCkjANDsyzbWcrq3WXcdFYW0RE9P/7X0dQbKkNV873pAiDDmx4I7AlYLtdL6yq9AxGZBcwCGDJkSGeLGGNMjzltaCqnDU1tl/b1zwzvsFxDUwuvbcgnKSaSM0ak8e9VudTUN3PBSf0Ynp7Awk37+NY/VzIqI5Gy6gauf3Rpu/V/8/oWZkwaRMH+OhZs3AfAy+vyiY7wsaukmnumn0xqfBRvbNpHhF8YN7APl58yoMc/b9i6zqqqikiPFWtUdQ4wB1zJoqe2a4wxn0RUhI/p49vOcW84fWi7+ReOyWDDzy8hJtJPTUMTL6/NJy7aT1ZaPDGRfu5/7WOeWbab1Pgovn3uCE7KTOJnL6wnOS6KjKQYvv30qgPvg8K0cf2PiWCxT0QyA6qhCr30PGBwwHKDvLQ8XFVUYPqSXsinMcb0mtYh5eOiIpgxeXC7eX+fObnDBYmXj8sEoLGlhb++lU1KfBTXTR5CbJSfloPck/6T6O1bdM0HZnrTM4GXAtK/Is5UoMKrrloAXCwiKSKSAlzspRljzHEj+AJDn0/w+YToCD8/uHg0Xz1rGLFR/gPzQiFkJQsReRZXKugrIrnAXcD9wDwRuRnIAWZ4i7+K6wmVjes6+1UAVS0VkXuA5d5yv1DV0lDl2RhjTOfsojxjjDHAwXtD2Z3ijTHGdMuChTHGmG5ZsDDGGNMtCxbGGGO6ZcHCGGNMtyxYGGOM6dYx2XVWRIpw13Ecqb5AcQ9lpydZvg6P5evwHa15s3wdniPN11BVTe9sxjEZLD4pEVnRVV/jcLJ8HR7L1+E7WvNm+To8ociXVUMZY4zplgULY4wx3bJg0bk54c5AFyxfh8fydfiO1rxZvg5Pj+fL2iyMMcZ0y0oWxhhjumXBwhhjTLcsWAQQkUtFZIuIZIvI7DDmY7CILBaRTSKyUURu9dLvFpE8EVnjPS4LU/52ich6Lw8rvLRUEXlTRLZ5zym9nKfRAftljYjsF5HbwrHPRORxESkUkQ0BaZ3uH++GXw96v7l1IjKxl/P1WxHZ7L33CyKS7KVniUhtwH57JFT5OkjeuvzuROTH3j7bIiKX9HK+ngvI0y4RWeOl99o+O8gxInS/M1W1h2u38QPbgeFAFLAWGBOmvGQCE73pRGArMAa4G/jRUbCvdgF9g9J+A8z2pmcDvw7zd1kADA3HPgPOASYCG7rbP7ibfr0GCDAV+KiX83UxEOFN/zogX1mBy4Vpn3X63Xn/hbVANDDM+9/6eytfQfN/D/xvb++zgxwjQvY7s5JFmylAtqruUNUGYC4wPRwZUdV8VV3lTVcCHwMDD75W2E0HnvCmnwCuCmNeLgC2q+onuYr/iKnqO0DwHR272j/TgSfVWQoki7s/fa/kS1XfUNUm7+VS3H3ue10X+6wr04G5qlqvqjtxd9ic0tv5Enev0xnAs6F474M5yDEiZL8zCxZtBgJ7Al7nchQcoEUkC5gAfOQlfdcrRj7e21U9ARR4Q0RWisgsLy1D3X3TwZ3VZ4QnawBcR/s/8NGwz7raP0fT7+5ruLPPVsNEZLWIvC0inwlTnjr77o6WffYZYJ+qbgtI6/V9FnSMCNnvzILFUUxEEoB/A7ep6n7gYWAEMB7IxxWBw+FsVZ0ITANuEZFzAmeqK/eGpU+2iEQBVwL/8pKOln12QDj3T1dE5KdAE/C0l5QPDFHVCcAPgGdEJKmXs3XUfXdBrqf9SUmv77NOjhEH9PTvzIJFmzxgcMDrQV5aWIhIJO5H8LSq/gdAVfeparOqtgCPEqKid3dUNc97LgRe8PKxr7VY6z0XhiNvuAC2SlX3eXk8KvYZXe+fsP/uROQm4HLgBu8Ag1fFU+JNr8S1C5zQm/k6yHd3NOyzCOALwHOtab29zzo7RhDC35kFizbLgVEiMsw7O70OmB+OjHh1oY8BH6vqHwLSA+sYPw9sCF63F/IWLyKJrdO4BtINuH0101tsJvBSb+fN0+5s72jYZ56u9s984Cteb5WpQEVANULIicilwP8AV6pqTUB6uoj4venhwChgR2/ly3vfrr67+cB1IhItIsO8vC3rzbwBFwKbVTW3NaE391lXxwhC+TvrjZb7T8sD12NgK+6M4KdhzMfZuOLjOmCN97gMeApY76XPBzLDkLfhuJ4oa4GNrfsJSAMWAduAhUBqGPIWD5QAfQLSen2f4YJVPtCIqxu+uav9g+ud8lfvN7cemNTL+crG1WW3/s4e8Za92vt+1wCrgCvCsM+6/O6An3r7bAswrTfz5aX/H/CtoGV7bZ8d5BgRst+ZDfdhjDGmW1YNZYwxplsWLIwxxnTLgoUxxphuWbAwxhjTLQsWxhhjumXBwpjDICLN0n502x4bndgbtTRc14EYc1AR4c6AMZ8ytao6PtyZMKa3WcnCmB7g3dfgN+Lu87FMREZ66Vki8pY3GN4iERnipWeIu3/EWu9xprcpv4g86t2j4A0RifWW/75374J1IjI3TB/THMcsWBhzeGKDqqGuDZhXoarjgL8Af/TS/gw8oaqn4Abpe9BLfxB4W1VPxd0vYaOXPgr4q6qOBcpxVwWDuzfBBG873wrVhzOmK3YFtzGHQUSqVDWhk/RdwPmqusMb4K1AVdNEpBg3TEWjl56vqn1FpAgYpKr1AdvIAt5U1VHe6zuBSFW9V0ReB6qAF4EXVbUqxB/VmHasZGFMz9Eupg9HfcB0M23tip/Dje0zEVjujXpqTK+xYGFMz7k24PlDb/oD3AjGADcA73rTi4BvA4iIX0T6dLVREfEBg1V1MXAn0AfoULoxJpTs7MSYwxMrImsCXr+uqq3dZ1NEZB2udHC9l/Y94B8icgdQBHzVS78VmCMiN+NKEN/GjW7aGT/wTy+gCPCgqpb32Ccy5hBYm4UxPcBrs5ikqsXhzosxoWDVUMYYY7plJQtjjDHdspKFMcaYblmwMMYY0y0LFsYYY7plwcIYY0y3LFgYY4zp1v8HLelezGvXnlkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"9Vfhumrqqaxu","executionInfo":{"status":"ok","timestamp":1644312275805,"user_tz":-210,"elapsed":5314,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}}},"source":["from keras.models import load_model\n","# LOAD BEST MODEL to evaluate the performance of the model\n","save_dir = os.path.join(root_path, \"final_data/AQ1-saved_model\")\n","fold_var = 1\n","\n","# load model\n","model = load_model(os.path.join(save_dir, get_model_name(fold_var)))\n","\n","# define an encoder model (without the decoder)\n","encoder = Model(inputs=visible, outputs=bottleneck)\n","\n","# encode the train data\n","X_train_encode = encoder.predict(Xstrain)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtM4TL5Drjxa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644312319324,"user_tz":-210,"elapsed":40183,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"d71e0e54-239f-4ced-fc5c-0f10a13153a4"},"source":["# define the model\n","from sklearn.svm import SVR\n","reg = SVR(kernel='rbf', C=100, gamma='auto', epsilon=.1)\n","# fit the model on the training set\n","reg.fit(X_train_encode, ytrain)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["SVR(C=100, gamma='auto')"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"hfIh3Sy_4dil"},"source":["# Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jS0agkTJDAyq","executionInfo":{"status":"ok","timestamp":1644312353866,"user_tz":-210,"elapsed":30835,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"d51991c3-af65-404e-830c-c3f48abd66c1"},"source":["########## Train\n","dftrain[\"y_pred\"] = reg.predict(X_train_encode)\n","\n","def NominalPM(row):\n","    return row[\"y_pred\"]/((1-row[\"RH\"])**(-1))\n","dftrain[\"PMp\"] = dftrain.apply(NominalPM, axis = 1)\n","RMSE = np.round(mean_squared_error(dftrain[\"PM2.5\"], dftrain[\"PMp\"], squared=False), 2)\n","MAE = np.round(mean_absolute_error(dftrain[\"PM2.5\"], dftrain[\"PMp\"]), 2)\n","print (\"RMSE: \", RMSE)\n","print (\"MAE: \", MAE)\n","from scipy.stats import pearsonr\n","corr, _ = pearsonr(dftrain[\"y_pred\"], dftrain[\"PMc\"])\n","print('Pearsons R2 correlation: %.2f' % corr**2)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE:  7.97\n","MAE:  6.03\n","Pearsons R2 correlation: 0.83\n"]}]},{"cell_type":"markdown","metadata":{"id":"wiZ6RA7FrhNI"},"source":["# Test "]},{"cell_type":"code","metadata":{"id":"Udg1eJlysahl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644312364901,"user_tz":-210,"elapsed":8787,"user":{"displayName":"Hossein Bagheri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04221406360538277957"}},"outputId":"ef03563a-e126-4331-b24c-3ceb39ea7891"},"source":["name = 'test' + \".csv\"\n","path = os.path.join(root_path, 'final_data', name)\n","dftest = pd.read_csv(path)\n","\n","\n","Xtest = dftest[[varAOD, 'lat', 'long', 'Prob_bestm','d2m', 't2m', 'blh',\n","                  'sp', 'lai_hv', 'ws10', 'wd10', 'uvb', 'RH', 'DOY']]\n","ytest = dftest.loc[:,['PMc']]\n","ytest = ytest.to_numpy()\n","Xstest = scaler.fit_transform(Xtest)\n","\n","start = time.time()\n","X_test_encode = encoder.predict(Xstest)\n","dftest[\"y_pred\"] = reg.predict(X_test_encode)\n","print(\"Time elapsed: \", time.time() - start)\n","\n","dftest[\"PMp\"] = dftest.apply(NominalPM, axis = 1)\n","RMSE = np.round(mean_squared_error(dftest[\"PM2.5\"], dftest[\"PMp\"], squared=False),2)\n","MAE = np.round(mean_absolute_error(dftest[\"PM2.5\"], dftest[\"PMp\"]),2)\n","print (\"RMSE: \", RMSE)\n","print (\"MAE: \", MAE)\n","corr, _ = pearsonr(dftest[\"y_pred\"], dftest[\"PMc\"])\n","print('Pearsons R2 correlation: %.2f' % corr**2)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Time elapsed:  7.617049217224121\n","RMSE:  9.75\n","MAE:  7.32\n","Pearsons R2 correlation: 0.68\n"]}]}]}